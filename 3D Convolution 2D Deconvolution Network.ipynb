{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.utils as utils\n",
    "from torch import autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(linewidth=30)\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "num_epochs = 100\n",
    "batch_size = 20\n",
    "learning_rate = 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/'\n",
    "raw_dir = os.path.join(data_dir, 'raw/')\n",
    "img_dir = os.path.join(data_dir, 'image/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "list_data = []\n",
    "list_label = []\n",
    "\n",
    "for filename in os.listdir(raw_dir):\n",
    "    isovalue = int(filename.split('_')[1].strip('.raw'))\n",
    "\n",
    "    f = np.fromfile(raw_dir + filename, dtype='uint8')\n",
    "    f = (f.astype('float') - isovalue / 2) / 255\n",
    "    raw_img = torch.Tensor(f).reshape([1, 64, 64, 64])\n",
    "    list_data.append(raw_img)\n",
    "\n",
    "    if os.path.isfile(img_dir + filename.replace('.raw', '.png')):\n",
    "        item = filename.replace('.raw', '.png')\n",
    "        im = transform(Image.open(img_dir + item))\n",
    "        list_label.append(im)\n",
    "\n",
    "tensor_data = torch.stack(list_data)\n",
    "tensor_label = torch.stack(list_label)\n",
    "\n",
    "dataset = utils.data.TensorDataset(tensor_data, tensor_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4800, 1, 64, 64, 64]), torch.Size([4800, 3, 64, 64]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_data.shape, tensor_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 3200\n",
    "\n",
    "batch_size = 16\n",
    "val_split = 0.2\n",
    "shuffle_dataset = True\n",
    "random_seed = 42\n",
    "\n",
    "indices = list(range(sample_size))\n",
    "split = int(np.floor(val_split * sample_size))\n",
    "\n",
    "if shuffle_dataset:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "train_indices, valid_indices = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = utils.data.SubsetRandomSampler(train_indices)\n",
    "valid_sampler = utils.data.SubsetRandomSampler(valid_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           sampler=train_sampler)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correct_number(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        # Convolution 1\n",
    "        self.conv1 = nn.Conv3d(1, 16, kernel_size=3, padding=1)\n",
    "        nn.init.xavier_uniform(self.conv1.weight)\n",
    "        self.max1 = nn.MaxPool3d(kernel_size=(2, 2, 2),\n",
    "                                 stride=(2, 2, 2),\n",
    "                                 return_indices=True)\n",
    "\n",
    "        # Convolution 2\n",
    "        self.conv2 = nn.Conv3d(16, 32, kernel_size=3, padding=1)\n",
    "        nn.init.xavier_uniform(self.conv2.weight)\n",
    "        self.max2 = nn.MaxPool3d(kernel_size=(2, 2, 2),\n",
    "                                 stride=(2, 2, 2),\n",
    "                                 return_indices=True)\n",
    "\n",
    "        # Convolution 3\n",
    "        self.conv3 = nn.Conv3d(32, 64, kernel_size=3, padding=1)\n",
    "        nn.init.xavier_uniform(self.conv3.weight)\n",
    "        self.max3 = nn.MaxPool3d(kernel_size=(2, 2, 2),\n",
    "                                 stride=(2, 2, 2),\n",
    "                                 return_indices=True)\n",
    "\n",
    "        # Convolution 4\n",
    "        self.conv4 = nn.Conv3d(64, 128, kernel_size=3, padding=1)\n",
    "        nn.init.xavier_uniform(self.conv4.weight)\n",
    "        self.max4 = nn.MaxPool3d(kernel_size=(2, 2, 2),\n",
    "                                 stride=(2, 2, 2),\n",
    "                                 return_indices=True)\n",
    "\n",
    "        # Fully Connected / Dense Layer 1\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4 * 4, 128 * 4 * 4)\n",
    "\n",
    "        # De Convolution 1\n",
    "        self.maxUn1 = torch.nn.MaxUnpool2d(2, stride=2)\n",
    "        self.deconv1 = torch.nn.ConvTranspose2d(128, 64, 3, padding=1)\n",
    "\n",
    "        # De Convolution 2\n",
    "        self.maxUn2 = torch.nn.MaxUnpool2d(2, stride=2)\n",
    "        self.deconv2 = torch.nn.ConvTranspose2d(64, 32, 3, padding=1)\n",
    "\n",
    "        # De Convolution 3\n",
    "        self.maxUn3 = torch.nn.MaxUnpool2d(2, stride=2)\n",
    "        self.deconv3 = torch.nn.ConvTranspose2d(32, 16, 3, padding=1)\n",
    "\n",
    "        # De Convolution 4\n",
    "        self.maxUn4 = torch.nn.MaxUnpool2d(2, stride=2)\n",
    "        self.deconv4 = torch.nn.ConvTranspose2d(16, 3, 3, padding=1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        out = F.leaky_relu(self.conv1(data))\n",
    "        size1 = out[:, :, 0, :, :].size()\n",
    "        out, indices1 = self.max1(out)\n",
    "        \n",
    "        out = F.leaky_relu(self.conv2(out))\n",
    "        size2 = out[:, :, 0, :, :].size()\n",
    "        out, indices2 = self.max2(out)\n",
    "        \n",
    "        out = F.leaky_relu(self.conv3(out))\n",
    "        size3 = out[:, :, 0, :, :].size()\n",
    "        out, indices3 = self.max3(out)\n",
    "        \n",
    "        out = F.leaky_relu(self.conv4(out))\n",
    "        size4 = out[:, :, 0, :, :].size()\n",
    "        out, indices4 = self.max4(out)\n",
    "        \n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = F.leaky_relu(self.fc1(out))\n",
    "        out = out.view(16, 128, 4, 4)\n",
    "        \n",
    "        indices1 = flatten_indices(indices1)\n",
    "        indices2 = flatten_indices(indices2)\n",
    "        indices3 = flatten_indices(indices3)\n",
    "        indices4 = flatten_indices(indices4)\n",
    "\n",
    "        out = self.maxUn1(out, indices4, output_size=size4)\n",
    "        out = F.leaky_relu(self.deconv1(out))\n",
    "        \n",
    "        out = self.maxUn2(out, indices3, output_size=size3)\n",
    "        out = F.leaky_relu(self.deconv2(out))\n",
    "        \n",
    "        out = self.maxUn3(out, indices2, output_size=size2)\n",
    "        out = F.leaky_relu(self.deconv3(out))\n",
    "        \n",
    "        out = self.maxUn4(out, indices1, output_size=size1)\n",
    "        out = F.leaky_relu(self.deconv4(out))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_indices(indices):\n",
    "    indices = indices[:, :, 0, :, :]\n",
    "    max = indices.size()[2] * indices.size()[3] * 4\n",
    "    return (indices.int() - ((indices >= max).int() * max)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import pytorch_msssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  import sys\n",
      "/opt/anaconda/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  \n",
      "/opt/anaconda/lib/python3.7/site-packages/ipykernel_launcher.py:21: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "/opt/anaconda/lib/python3.7/site-packages/ipykernel_launcher.py:28: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 total_loss: 29.378464579582214\n",
      "epoch: 1 total_loss: 18.09668856859207\n",
      "epoch: 2 total_loss: 14.076175168156624\n",
      "epoch: 3 total_loss: 12.400116141885519\n",
      "epoch: 4 total_loss: 10.590228825807571\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(0):\n",
    "    network = Network()\n",
    "    optim = optim.Adam(network.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(5):\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "\n",
    "        for volume, image in train_loader:        \n",
    "            pred = network(volume)\n",
    "            loss = pytorch_msssim.msssim(pred, image, normalize=True)\n",
    "    \n",
    "            network.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(\"epoch:\", epoch, \"total_loss:\", total_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
